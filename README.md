# PromptFoo Quickstart: Funny Tweet Evaluator

This repo shows how to use PromptFoo to evaluate and compare responses from different LLMs using prompt variations and automated scoring.

This example compares OpenAI's gpt-4o and gpt-4o-mini on their ability to generate funny tweets about different topics.

PromptFoo is a command-line tool and framework for:

✅ Testing and improving prompt quality

✅ Comparing model outputs across providers (OpenAI, Claude, HuggingFace, etc.)

✅ Defining rules and rubrics to automatically grade responses

✅ Running evaluations via terminal or browser

✅ Tracking prompt performance over time

Use it to systematically benchmark prompts for use cases like summarization, classification, creative writing, RAG, or agent chains.


---

## Setup Instructions

### 1. Install Node.js (if needed)

[Download Node.js](https://nodejs.org/en/download) if it's not installed.

Check with:

```bash
node -v
```

### 2. Install PromptFoo CLI

Install PromptFoo globally using npm:

```bash
npm install -g promptfoo
```




